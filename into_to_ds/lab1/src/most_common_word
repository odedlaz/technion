#!/usr/bin/env bash
book_path=${1:-""}

# print most frequent word, least frequent word & longest word
function print_stats() {

   title="Statistics for \"$1\""
   underline=$(head -c ${#title} < /dev/zero | tr '\0' '#')
   echo -e "$title\n$underline\n"
   # 1. replace all punctuation and spaces with new line
   # 2. remove all non alphanumeric characters
   # 3. make everything lowercase
   # 4. sort
   words=$(tr -s '[:punct:][:space:]' '\n'< "$1" | \
           tr -cd '[:alpha:]\n' | \
           tr '[:upper:]' '[:lower:]' | \
           sort)
   # 1. count all uniq occurences, with the amount they appeared
   # 2. sort the output according to the amount they appeared in
   freq=$(echo "$words" | \
          uniq -c | sort -rn)

   # take the first value (most frequent), and print
   echo "$freq" | head -n 1 | \
      awk -F' ' '{printf "Most frequent word is \"%s\" (appeared %s times)\n",$2,$1}'

   # take the last value (leastt frequent), and print
   echo "$freq" | tail -n 1 | \
      awk -F' ' '{printf "Least frequent word is \"%s\" (appeared %s times)\n",$2,$1}'

   # 1. filter non unique words
   # 2. print the length of every word in the same format like 'uniq -c'
   # 3. sort like previous lines
   # 4. print longest word
   echo "$words" | \
      uniq | \
      awk '{ printf "%s %s\n",length($0),$0 }' | \
      sort -rn | \
      head -n 1 | \
      awk -F' ' '{printf "Longest word is \"%s\" (%s characters)\n",$2,$1}'
}

if ! test -z "$book_path"; then
   if ! test -f "$book_path"; then
      echo "file doesn't exist at given path"
      exit 1
   fi
   print_stats "$book_path"
   exit 0
fi

if ! find chapters/* -type f &> /dev/null; then
   echo "chapter files weren't generated."
   exit 1
fi

# iterate all book chapters and print their stats
for chapter in chapters/*; do
   printf "%s\n" "$(print_stats "$chapter")"
done
